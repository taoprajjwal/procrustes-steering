{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73bfe62-91af-43fd-bed8-efb3a311b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pb2276/.conda/envs/gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import Dataset\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774d8b2-8363-47a2-baa2-62365d31b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "access_token = \"hf_GsgagQCljYqoWKqZXHEMmvngztRpTFYmuxk\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",token=access_token)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",token=access_token).to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95709640-300f-4443-b482-29f94b8f375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e290b4-0522-4c96-a539-3a9b0de271d9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1a5a15-c311-4313-8521-7798f23be12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/datasets/pyvene/axbench-conceptFD/resolve/main/2b/l10/train/data.parquet -o train.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7366664-c488-44a9-a938-8840df0e2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181ed6b6-660d-4478-9759-672c460cb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[\"concept_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fbbea33-7c9f-4b63-a18c-7732af6d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = df[ df[\"concept_id\"]== -1].sample(72)\n",
    "b_df = df[ df[\"concept_id\"]== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e90754b-754c-4fe6-85b2-1cb9a6c87412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the main thing this neuron does is find references to \"domestic\" contexts or tasks, and then outputs words related to navigation or scene management, suggesting a function related to organizing or structuring domestic life or tasks within a broader framework.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"concept_id\"]==1][\"output_concept\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a022e-3005-4f03-a935-f611de771695",
   "metadata": {},
   "source": [
    "# Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d9d98ce-7ba7-48b9-8d53-70dd5beb1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"output\"], padding=True, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e40c216-f65f-41af-80a3-37caecf4c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ds = Dataset.from_pandas(a_df)\n",
    "b_ds = Dataset.from_pandas(b_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b19fee6-c874-47dc-9588-46405cc82575",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embds_from_ds(ds, batch_size=8, embd_size=4096):\n",
    "    embds_out = np.empty((0,embd_size))\n",
    "\n",
    "    captured_activations={}\n",
    "    def capture_hook(module, input, output):\n",
    "        captured_activations['hidden'] = output[0].detach().cpu().numpy()\n",
    "    target_layer = 16\n",
    "    hook_handle = model.model.layers[target_layer].register_forward_hook(capture_hook)\n",
    "\n",
    "    for batch in ds.iter(batch_size=batch_size):\n",
    "        tokens=tokenize(batch)\n",
    "        last_token_idx = (torch.sum(tokens[\"attention_mask\"], dim=1) -1).cpu().numpy()\n",
    "        out = model(**tokens)\n",
    "        batch_embds = captured_activations[\"hidden\"][np.arange(batch_size), last_token_idx, :]\n",
    "        embds_out = np.concatenate((embds_out, batch_embds))\n",
    "        \n",
    "    hook_handle.remove()\n",
    "    return embds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9650fa09-b76f-4eb8-899e-46a86396f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "embds_a = get_embds_from_ds(a_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caf0b575-4347-4368-bbfb-54a04b9a9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "embds_b = get_embds_from_ds(b_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ffcfc9-4c38-412a-9d80-b9ef752029ec",
   "metadata": {},
   "source": [
    "# Get rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "361272fd-5c01-4b24-b288-3ef96c1d2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procustes_matrix(concept1_embd, concept2_embd):\n",
    "\n",
    "    ## ORDER MATTERS HERE!! MAKE SURE CONCEPT 2 IS THE ONE THAT YOU ARE STEERING TOWARDS!!\n",
    "    u, _, v = np.linalg.svd(concept1_embd.T @ concept2_embd)\n",
    "    return v.T @ u.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10802f21-eda6-41da-a961-086cdea2f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = get_procustes_matrix(embds_a, embds_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dea0162-3855-419e-a818-b16b43a2f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.from_numpy(M).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d3f62b-ed2c-428b-8a9f-96983a713288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666dd07c-c6c3-490d-a7f7-43d8912a9805",
   "metadata": {},
   "source": [
    "# Apply steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6289c555-9b4d-4472-a1ab-80889e883a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "s={}\n",
    "def steering_hook(module, input, output):\n",
    "    s[\"test\"]=output\n",
    "    new_o = output[0]@M\n",
    "    return (new_o, output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcb49cd6-e532-4971-91f7-2fedefeaf3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaDecoderLayer(\n",
       "  (self_attn): LlamaSdpaAttention(\n",
       "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (mlp): LlamaMLP(\n",
       "    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "    (act_fn): SiLU()\n",
       "  )\n",
       "  (input_layernorm): LlamaRMSNorm()\n",
       "  (post_attention_layernorm): LlamaRMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04ea7986-2e45-4788-8ad3-172b68b04cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"What is the framework laptop like?\"\n",
    "inputs=tokenizer(test_input, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8909641d-6ce5-47f5-ba6a-dd822657fa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  1724,   338,   278,  6890, 19022,   763, 29973]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea7e3642-be1d-4904-abe5-ed70faa46743",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e5dc48e-2ed2-411d-a986-6d3ba9ccebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> What is the framework laptop like?\n",
      "I’m going to take a quick look at the framework laptop. It’s an interesting concept that could potentially revolutionize the laptop market. The framework laptop is a modular laptop that you can customize to your needs. You can add or remove components as needed, and it’s very easy to upgrade or repair.\n",
      "The framework laptop is a bit like a Lego set for laptops. You can build it to your exact specifications, and then take it apart and upgrade it as needed. It’s a very flexible and versatile laptop, and it could be a game-changer for the laptop\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "974775ae-2dd4-4195-9990-cc30499215fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same target layer as the prev one!\n",
    "hook_handle = model.model.layers[16].register_forward_hook(steering_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec1086e2-2bce-4dd4-af37-b0b94f67a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "608e1a45-e3bf-4002-99f5-0b24997e6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> What is the framework laptop like?OOa,OO\u0000OO;OOOOO\u0000\u0000O andINOO</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "088b88c8-1b4c-44e5-b21d-d16b4249b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1806a7-96a0-4c14-b58f-050ce4389ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5457bf1c-52be-4f1d-84bf-7e57d9eb0e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5854,  0.4171,  0.1461,  ..., -0.1151, -0.4019,  0.2974]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "caa1d966-c750-47a8-a5ba-f09335fb326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6901,  0.9900, -0.7350,  ..., -0.6818,  0.2636,  0.1547]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s[\"test\"][0]@M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49ad0134-67e8-4955-9ffb-aa383bfd5e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35877d42-f8d9-436c-854d-2695df504c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
